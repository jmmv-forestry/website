---
title: "Using C++ templates to optimize code"
date: 2009-05-07 18:20:00 -0400
categories:
  - "c++"
  - "pin"
julipedia: 2009/05/using-c-templates-to-optimize-code.html
excerpt_separator: </p>
slug: using-c-templates-to-optimize-code
---
As part of the project I'm currently involved in at university, I started (re)writing a <a href="http://www.pintool.org/">Pin</a> tool to gather run-time traces of applications parallelized with OpenMP. This tool has to support two modes: one to generate a single trace for the whole application and one to generate one trace per parallel region of the application.<br /><br />In the initial versions of my rewrite, I followed the idea of the previous version of the tool: have a <tt>-split</tt> flag in the frontend that enables or disables the behavior described above.  This flag was backed by an abstract class, <tt>Tracer</tt>, and two implementations: <tt>PlainTracer</tt> and <tt>SplittedTracer</tt>.  The thread-initialization callback of the tool then allocated one of these objects for every new thread and the <i>per-instruction injected code</i> used a pointer to the interface to call the appropriate specialized instrumentation routine.  This pretty much looked like this:<pre>void<br />thread_start_callback(int tid, ...)<br />{<br />    if (splitting)<br />        tracers[tid] = new SplittedTracer();<br />    else<br />        tracers[tid] = new PlainTracer();<br />}<br /><br />void<br />per_instruction_callback(...)<br />{<br />    Tracer* t = tracers[PIN_ThreadId()];<br />    t->instruction_callback(...);<br />}</pre>I knew from the very beginning that such an implementation was going to be inefficient due to the pointer dereference at each instruction and the vtable lookup for the correct virtual method implementation.  However, it was a very quick way to move forward because I could reuse some small parts of the old implementation.<br /><br />There were two ways to optimize this: the first one involved writing different versions of <tt>per_instruction_callback</tt>, one for plain tracing and the other for splitted tracing, and then deciding which one to insert depending on the flag.  The other way was to use template metaprogramming.<br /><br />As you can imagine, this being C++, I opted to use template metaprogramming to heavily abstract the code in the Pin tool.  Now, I have an abstract core parametrized on the Tracer type.  When instantiated, I provide the correct Tracer class and the compiler does all the magic for me.  With this design, there is no need to have a parent Tracer class &mdash; though I'd welcome having C++0x concepts available &mdash;, and the callbacks can be easily inlined because there is no run-time vtable lookup.  It looks something like this:<pre>template< class Tracer ><br />class BasicTool {<br />    Tracer* tracers[MAX_THREADS];<br /><br />    Tracer* allocate_tracer(void) const = 0;<br /><br />public:<br />    Tracer*<br />    get_tracer(int tid)<br />    {<br />        return tracers[tid];<br />    }<br />};<br /><br />class PlainTool : public BasicTool< PlainTracer > {<br />    PlainTracer*<br />    allocate_tracer(void) const<br />    {<br />        return new PlainTracer();<br />    }<br /><br />public:<br />    ...<br />} the_plain_tool;<br /><br />// This is tool-specific, non-templated yet.<br />void<br />per_instruction_callback(...)<br />{<br />    the_plain_tool.get_tracer(PIN_ThreadId()).instruction_callback(...);<br />}</pre>What this design also does is force me to have two different Pin tools: one for plain tracing and another one for splitted tracing.  Of course, I chose it to be this way because I'm not a fan of run-time options (the <tt>-split</tt> flag).  Having two separate tools with well-defined, non-optional features makes testing much, much easier and... follows the Unix philosophy of having each tool do exactly one thing, but doing it right!<br /><br />Result: around a 15% speedup.  And C++ was supposed to be slow? ;-)  You just need to know what the language provides you and choose wisely.  (Read: my initial, naive prototype had a run-time of 10 minutes to trace part of a small benchmark; after several rounds of optimizations, it's down to 1 minute and 50 seconds to trace the <i>whole</i> benchmark!)<br /><br />Disclaimer: The code above is an oversimplification of what the tool contains.  It is completely fictitious and obviates many details.  I will admit, though, that the real code is too complex at the moment.  I'm looking for ways to simplify it.
